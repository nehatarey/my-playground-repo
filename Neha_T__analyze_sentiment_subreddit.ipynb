{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehatarey/my-playground-repo/blob/main/Neha_T__analyze_sentiment_subreddit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zEhmL9rDA7A"
      },
      "source": [
        "<p align = \"center\" draggable=”false” ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
        "     width=\"200px\"\n",
        "     height=\"auto\"/>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v98DUJvDA7K"
      },
      "source": [
        "# Reddit and HuggingFace Starter Kit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VhaENOpDA7L"
      },
      "source": [
        "In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( 🤗 the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7K0um39DA7M"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ADQB6z3DA7N"
      },
      "source": [
        "At the end of the session, you will "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PA56E03DA7O"
      },
      "source": [
        "- know how to work with APIs\n",
        "- feel more comfortable navigating thru documentation, even inspecting the source code\n",
        "- understand what a `pipeline` object is in HuggingFace\n",
        "- perform sentiment analysis using `pipeline`\n",
        "- run a python script in command line and get the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "TdGvCp48DA7P"
      },
      "source": [
        "## How to Submit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "c4EpAou9DA7R"
      },
      "source": [
        "- At the end of each task, commit* the work into your own remote repo\n",
        "- After completing all three tasks, make sure to push the notebook containing all code blocks and output cells to your remote repo\n",
        "- Submit the link to the notebook in Canvas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "VFb_BRd3DA7T"
      },
      "source": [
        "\\***NEVER** commit a notebook displaying errors unless it is instructed otherwise. However, commit often; recall git ABC = **A**lways **B**e **C**ommitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuaW8hl2DA7U"
      },
      "source": [
        "## Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "wqfVblqjDA7W"
      },
      "source": [
        "### Task I: Instantiate a Reddit API Object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "-E65HDkxDA7X"
      },
      "source": [
        "The first task is to instantiate a Reddit API object using [PRAW](https://praw.readthedocs.io/en/stable/), through which you will retrieve data. PRAW is a wrapper for [Reddit API](https://www.reddit.com/dev/api) that makes interacting with the Reddit API easier unless you are already an expert of [`requests`](https://docs.python-requests.org/en/latest/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "_sC-QDBgDA7X"
      },
      "source": [
        "#### 0.  Get updates from `FourthBrain/MLE-7`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "n47Xypf3DA7Y"
      },
      "source": [
        "Under your forked local repo, **fetch** and download new updates from repo `FourthBrain/MLE-7` locally so you can start development. \n",
        "    \n",
        "<details>\n",
        "<summary>If you haven't added `FourthBrain/MLE-7` as a remote repo, click here for instructions:</summary>   \n",
        "You fork repo `FourthBrain/MLE-7` to `yourhandle/MLE-7`, clone it locally, and now you are under directory `MLE-7`. By default, you will see one server name `origin` pointing to your repo:  \n",
        "    \n",
        "```\n",
        "$git remote -v \n",
        "origin  git@github.com:yourhandle/MLE-7.git (fetch)\n",
        "origin  git@github.com:yourhandle/MLE-7.git (push)\n",
        "```\n",
        "\n",
        "Think of fetch = read and push = write. \n",
        "\n",
        "Now add `FourthBrain/MLE-7` as a remote repo\n",
        "\n",
        "```\n",
        "$git add remote fourthbrain git@github.com:FourthBrain/MLE-7.git\n",
        "$git remote -v\n",
        "fourthbrain\tgit@github.com:FourthBrain/MLE-7.git (fetch)\n",
        "fourthbrain\tgit@github.com:FourthBrain/MLE-7.git (push)\n",
        "origin git@github.com:yourhandle/MLE-7.git (fetch)\n",
        "origin git@github.com:yourhandle/MLE-7.git (push)\n",
        "```\n",
        "\n",
        "then before each session starts, run `git fetch fourthbrain` to get updates (why not `git pull`?).\n",
        "\n",
        "check out [Working with Remotes](https://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes) for more explanations.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "IQW8f5D6DA7a"
      },
      "source": [
        "#### 1. Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "a1OdZipiDA7a"
      },
      "source": [
        "```\n",
        "conda activate {your_virtual_environment_name}\n",
        "pip install -U transformers praw torch numpy pandas\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "x6NEgkDLDA7b"
      },
      "source": [
        "####  2. Create a new app on Reddit "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "9pbpm6tUDA7b"
      },
      "source": [
        "Create a new app on Reddit and save secret tokens; refer to [post in medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "-iXYRjFoDA7c"
      },
      "source": [
        "- Create a Reddit account if you don't have one, log into your account.\n",
        "- To access the API, we need create an app. Slight updates, on the website, you need to navigate to `preference` > `app`, or click [this link](https://www.reddit.com/prefs/apps) and scroll all the way down. \n",
        "- Click to create a new app, fill in the **name**, choose `script`, fill in  **description** and **redirect url** ( The redirect URI is where the user is sent after they've granted OAuth access to your application; more info [here](and details are in [](https://github.com/reddit-archive/reddit/wiki/OAuth2) for our purpose, you can enter some random url, e.g., www.google.com; ) as shown below.\n",
        "    <div>\n",
        "    <img src=\"./img/reddit_create_app.png\" width=\"500\"/>\n",
        "    </div>   \n",
        "- Jolt down `client_id` (left upper corner) and `client_secret` \n",
        "    <div>\n",
        "    <img src=\"./img/reddit_secret_tokens.png\" width=\"300\"/>\n",
        "    </div>\n",
        "\n",
        "- Create `secrets.py` in the same directory with this notebook, fill in `client_id` and `secret_id` obtained from the last step. We will need to import those constants in the next step.\n",
        "    ```\n",
        "    REDDIT_API_CLIENT_ID = {client_id}\n",
        "    REDDIT_API_CLIENT_SECRET = {secret_id}\n",
        "    REDDIT_API_USER_AGENT = {can_be_any_string, e.g., : \"BotBot\"}\n",
        "    ```\n",
        "- Add `secrets.py` to your `.gitignore` file if not already done. NEVER push credentials to a repo, private or public. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sent_analyzer"
      ],
      "metadata": {
        "id": "uoVleR4ETrpl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "uZL0rWwdDA7d"
      },
      "source": [
        "#### 3. Instantiate a `Reddit` object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Pwn9ffe0DA7e"
      },
      "source": [
        "Now you are ready to create a read-only `Reddit` instance. Refer to [documentation](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) when necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "FW-eYDZ7DA7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "a5bc617f-de72-43d0-d595-441b9c0dd197"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-64ff2d7c33ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msecrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a Reddit object which allows us to interact with the Reddit API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'praw'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import praw\n",
        "import secrets\n",
        "\n",
        "# Create a Reddit object which allows us to interact with the Reddit API\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=secrets.REDDIT_API_CLIENT_ID,        # YOUR CODE HERE\n",
        "    client_secret=secrets.REDDIT_API_CLIENT_SECRET,# YOUR CODE HERE\n",
        "    user_agent=secrets.REDDIT_API_USER_AGENT,      # YOUR CODE HERE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "8VpTcfCtDA7h"
      },
      "outputs": [],
      "source": [
        "print(reddit) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEbDWk9nDA7i"
      },
      "source": [
        "<details>\n",
        "<summary>Expected output:</summary>   \n",
        "\n",
        "```<praw.reddit.Reddit object at 0x10f8a0ac0>```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "qqS7wxRTDA7i"
      },
      "source": [
        "#### 4. Instantiate a `subreddit` object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "I_zJC3FTDA7i"
      },
      "source": [
        "Lastly, create a `subreddit` object for your favorite subreddit and inspect the object. The expected output you will see ar from `r/machinelearning` unless otherwise specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "TiNyh8UDDA7j"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "gGgWomn_DA7j"
      },
      "source": [
        "What is the display name of the subreddit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "184svFIwDA7k"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWxzzDJRDA7k"
      },
      "source": [
        "<details>\n",
        "<summary>Expected output:</summary>   \n",
        "\n",
        "    machinelearning\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ubFePeIODA7k"
      },
      "source": [
        "How about its title, is it different from the display name?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "inHLfVCzDA7l"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFAC6BLoDA7l"
      },
      "source": [
        "<details>\n",
        "<summary>Expected output:</summary>   \n",
        "\n",
        "    Machine Learning\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "2hdgEpBlDA7l"
      },
      "source": [
        "Print out the description of the subreddit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "yQLM1CCJDA7m"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lQ8rU91DA7m"
      },
      "source": [
        "<details>\n",
        "<summary>Expected output:</summary>\n",
        "\n",
        "    **[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
        "    --------\n",
        "    +[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
        "    --------\n",
        "    +[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
        "    --------\n",
        "    +[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
        "    --------\n",
        "    +[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "1IYZHH7QDA7n"
      },
      "source": [
        "### Task II: Parse comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "SCPoFVDhDA7n"
      },
      "source": [
        "#### 1. Top Posts of All Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "fLkpj1FxDA7n"
      },
      "source": [
        "Find titles of top 10 posts of **all time** from your favorite subreddit. Refer to [Obtain Submission Instances from a Subreddit Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)) if necessary. Verify if the titles match what you read on Reddit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "BPfPBrGdDA7o"
      },
      "outputs": [],
      "source": [
        "# try run this line, what do you see? press q once you are done\n",
        "?subreddit.top "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "T-7CHVnkDA7o"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Nxo4ZYfwDA7p"
      },
      "source": [
        "<details> <summary>Expected output:</summary>\n",
        "\n",
        "    [Project] From books to presentations in 10s with AR + ML\n",
        "    [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
        "    [R] First Order Motion Model applied to animate paintings\n",
        "    [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
        "    [D] This AI reveals how much time politicians stare at their phone at work\n",
        "    [D] Types of Machine Learning Papers\n",
        "    [D] The machine learning community has a toxicity problem\n",
        "    [Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
        "    [P] Using oil portraits and First Order Model to bring the paintings back to life\n",
        "    [D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG)    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "G5EszBPQDA7q"
      },
      "source": [
        "#### 2. Top 10 Posts of This Week"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "EIxEmXu2DA7q"
      },
      "source": [
        "What are the titles of the top 10 posts of **this week** from your favorite subreddit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "IvsPhhvGDA7q"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "nHwqYBhlDA7r"
      },
      "source": [
        "<details><summary>Expected output:</summary>\n",
        "\n",
        "    [N] Ian Goodfellow, Apple’s director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said “I believe strongly that more flexibility would have been the best policy for my team.” He was likely the company’s most cited ML expert.\n",
        "    [R][P] Thin-Plate Spline Motion Model for Image Animation + Gradio Web Demo\n",
        "    [P] I’ve been trying to understand the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple’s version of MobileNet, and more directly on your phone's camera roll.\n",
        "    [R] Meta is releasing a 175B parameter language model\n",
        "    [N] Hugging Face raised $100M at $2B to double down on community, open-source & ethics\n",
        "    [P] T-SNE to view and order your Spotify tracks\n",
        "    [D] : HELP Finding a Book - A book written for Google Engineers about foundational Math to support ML\n",
        "    [R] Scaled up CLIP-like model (~2B) shows 86% Zero-shot on Imagenet\n",
        "    [D] Do you use NLTK or Spacy for text preprocessing?\n",
        "    [D] Democratizing Diffusion Models - LDMs: High-Resolution Image Synthesis with Latent Diffusion Models, a 5-minute paper summary by Casual GAN Papers\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "S80H3nWTDA7r"
      },
      "source": [
        "#### 3. Comment Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "mSK4H8apDA7s"
      },
      "source": [
        "Add comments to the code block below to describe what each line of the code does (Refer to [Obtain Comment Instances Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html) when necessary). The code is adapted from [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
        "\n",
        "The purpose is \n",
        "1. to understand what the code is doing \n",
        "2. start to comment your code whenever it is not self-explantory if you have not (others will thank you, YOU will thank you later 😊) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "YePeKatjDA7s"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from praw.models import MoreComments\n",
        "\n",
        "# YOUR COMMENT HERE\n",
        "top_comments = []\n",
        "\n",
        "# YOUR COMMENT HERE\n",
        "for submission in subreddit.top(limit=10):\n",
        "    # YOUR COMMENT HERE\n",
        "    for top_level_comment in submission.comments:\n",
        "        # YOUR COMMENT HERE\n",
        "        if isinstance(top_level_comment, MoreComments):\n",
        "            continue\n",
        "        # YOUR COMMENT HERE\n",
        "        top_comments.append(top_level_comment.body)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "kmBGW2TeDA7s"
      },
      "source": [
        "#### 4. Inspect Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "y5zvPNaFDA7t"
      },
      "source": [
        "How many comments did you extract from the last step? Examine a few comments. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "2_qUIcDrDA7t"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE  # the answer may vary 693 for r/machinelearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "4t6kw-2zDA7u"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "[random.choice(top_comments) for i in range(3)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir3UxS2EDA7u"
      },
      "source": [
        "<details> <summary>Some of the comments from `r/machinelearning` subreddit are:</summary>\n",
        "\n",
        "    ['Awesome visualisation',\n",
        "    'Similar to a stack or connected neurons.',\n",
        "    'Will this Turing pass the Turing Test?']\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "i6sjfprfDA7v"
      },
      "source": [
        "#### 5. Extract Top Level Comment from Subreddit `TSLA`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "9E7n2VEjDA7v"
      },
      "source": [
        "Write your code to extract top level comments from the top 10 topics of a time period, e.g., year, from subreddit `TSLA` and store them in a list `top_comments_tsla`.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "Xoz6ovQCDA7v"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "2YBAa6_tDA7w"
      },
      "outputs": [],
      "source": [
        "len(top_comments_tsla) # Expected: 174 for r/machinelearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "q-eMn6ZiDA7w"
      },
      "outputs": [],
      "source": [
        "[random.choice(top_comments_tsla) for i in range(3)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAYTB7cvDA7w"
      },
      "source": [
        "<details>\n",
        "<summary>Some of the comments from `r/TSLA` subreddit:</summary>\n",
        "\n",
        "    ['I bought puts',\n",
        "    '100%',\n",
        "    'Yes. And I’m bag holding 1200 calls for Friday and am close to throwing myself out the window']\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "CmmrKgkRDA7x"
      },
      "source": [
        "### Task III: Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "6zgtna7fDA7x"
      },
      "source": [
        "Let us analyze the sentiment of comments scraped from `r/TSLA` using a pre-trained HuggingFace model to make the inference. Take a [Quick tour](https://huggingface.co/docs/transformers/quicktour). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ZyVcVqbpDA7x"
      },
      "source": [
        "#### 1. Import `pipeline`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "FCtzyS03DA7y"
      },
      "outputs": [],
      "source": [
        "from transformers import # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "olZskA95DA7y"
      },
      "source": [
        "#### 2. Create a Pipeline to Perform Task \"sentiment-analysis\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "owbmul3SDA7y"
      },
      "outputs": [],
      "source": [
        "sentiment_model = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "l41mgDJBDA7z"
      },
      "source": [
        "#### 3. Get one comment from list `top_comments_tsla` from Task II - 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "dMhLp_xLDA7z"
      },
      "outputs": [],
      "source": [
        "comment = random.choice(top_comments_tsla)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "L8NZpe0XDA7z"
      },
      "outputs": [],
      "source": [
        "comment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOAyDimfDA70"
      },
      "source": [
        "The example comment is: `'Bury Burry!!!!!'`. Print out what you get. For reproducibility, use the same comment in the next step; consider setting a seed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Pqi2jNPUDA70"
      },
      "source": [
        "#### 4. Make Inference!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "a3mJBPF7DA70"
      },
      "outputs": [],
      "source": [
        "sentiment = # YOUR CODE HERE "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "VlwP5CD2DA71"
      },
      "source": [
        "What is the type of the output `sentiment`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "4Pe2_U0iDA71"
      },
      "source": [
        "```\n",
        "YOUR ANSWER HERE\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "c7DLq3kADA71"
      },
      "outputs": [],
      "source": [
        "print(f'The comment: {comment}')\n",
        "print(f'Predicted Label is {sentiment[0][\"label\"]} and the score is {sentiment[0][\"score\"]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh3fI0UPDA71"
      },
      "source": [
        "For the example comment, the output is:\n",
        "\n",
        "    The comment: Bury Burry!!!!!\n",
        "    Predicted Label is NEGATIVE and the score is 0.989"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rx1bcnvDA72"
      },
      "source": [
        "### Task IV: Put All Together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT9uoX92DA72"
      },
      "source": [
        "Let's pull all the piece together, create a simple script that does \n",
        "\n",
        "- get the subreddit\n",
        "- get comments from the top posts for given subreddit\n",
        "- run sentiment analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2cGt5DJDA73"
      },
      "source": [
        "#### Complete the Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_jMg-9LDA73"
      },
      "source": [
        "Once you complete the code, running the following block writes the code into a new Python script and saves it as `top_tlsa_comment_sentiment.py` under the same directory with the notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "Poe1-ViWDA73"
      },
      "outputs": [],
      "source": [
        "%%writefile top_tlsa_comment_sentiment.py\n",
        "\n",
        "import secrets\n",
        "import random\n",
        "\n",
        "from typing import Dict, List\n",
        "\n",
        "from praw import Reddit\n",
        "from praw.models.reddit.subreddit import Subreddit\n",
        "from praw.models import MoreComments\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "def get_subreddit(display_name:str) -> Subreddit:\n",
        "    \"\"\"Get subreddit object from display name\n",
        "\n",
        "    Args:\n",
        "        display_name (str): [description]\n",
        "\n",
        "    Returns:\n",
        "        Subreddit: [description]\n",
        "    \"\"\"\n",
        "    reddit = Reddit(\n",
        "        client_id=secrets.REDDIT_API_CLIENT_ID,        \n",
        "        client_secret=secrets.REDDIT_API_CLIENT_SECRET,\n",
        "        user_agent=secrets.REDDIT_API_USER_AGENT\n",
        "        )\n",
        "    \n",
        "    subreddit = # YOUR CODE HERE\n",
        "    return subreddit\n",
        "\n",
        "def get_comments(subreddit:Subreddit, limit:int=3) -> List[str]:\n",
        "    \"\"\" Get comments from subreddit\n",
        "\n",
        "    Args:\n",
        "        subreddit (Subreddit): [description]\n",
        "        limit (int, optional): [description]. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of comments\n",
        "    \"\"\"\n",
        "    top_comments = []\n",
        "    for submission in subreddit.top(limit=limit):\n",
        "        for top_level_comment in submission.comments:\n",
        "            if isinstance(top_level_comment, MoreComments):\n",
        "                continue\n",
        "            top_comments.append(top_level_comment.body)\n",
        "    return top_comments\n",
        "\n",
        "def run_sentiment_analysis(comment:str) -> Dict:\n",
        "    \"\"\"Run sentiment analysis on comment using default distilbert model\n",
        "    \n",
        "    Args:\n",
        "        comment (str): [description]\n",
        "        \n",
        "    Returns:\n",
        "        str: Sentiment analysis result\n",
        "    \"\"\"\n",
        "    sentiment_model = # YOUR CODE HERE\n",
        "    sentiment = sentiment_model(comment)\n",
        "    return sentiment[0]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    submission = # YOUR CODE HERE\n",
        "    comments = get_comments(submission)\n",
        "    comment = # YOUR CODE HERE\n",
        "    sentiment = run_sentiment_analysis(comment)\n",
        "    \n",
        "    print(f'The comment: {comment}')\n",
        "    print(f'Predicted Label is {sentiment[\"label\"]} and the score is {sentiment[\"score\"]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr0ssj2eDA74"
      },
      "source": [
        "Run the following block to see the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dGj5ufdDA74"
      },
      "outputs": [],
      "source": [
        "!python top_tlsa_comment_sentiment.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aySC-u7PDA75"
      },
      "source": [
        "<details><summary> Expected output:</summary>\n",
        "\n",
        "    No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
        "    The comment: When is DOGE flying\n",
        "    Predicted Label is POSITIVE and the score is 0.689\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "70e5a9886b02a227d3c83e17263e3a28d12f842d6950be488144931078452c0e"
    },
    "kernelspec": {
      "display_name": "py39_12",
      "language": "python",
      "name": "py39_12"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "Neha T_ analyze-sentiment-subreddit.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wqfVblqjDA7W",
        "IQW8f5D6DA7a",
        "x6NEgkDLDA7b",
        "uZL0rWwdDA7d",
        "qqS7wxRTDA7i",
        "1IYZHH7QDA7n",
        "SCPoFVDhDA7n",
        "G5EszBPQDA7q",
        "S80H3nWTDA7r",
        "kmBGW2TeDA7s",
        "i6sjfprfDA7v",
        "CmmrKgkRDA7x",
        "ZyVcVqbpDA7x",
        "olZskA95DA7y",
        "l41mgDJBDA7z",
        "Pqi2jNPUDA70",
        "3rx1bcnvDA72",
        "j2cGt5DJDA73"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}